{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Aprendizaje por refuerzo\n",
        "# Importación de bibliotecas"
      ],
      "metadata": {
        "id": "SBrmkE6hCR_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle"
      ],
      "metadata": {
        "id": "RfQd-sdDCvBD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clase juego :gestiona el juego y el entrenamiento"
      ],
      "metadata": {
        "id": "27l7Ny5jCre9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Game:\n",
        "    def __init__(self, player1, player2):\n",
        "        player1.symbol = 1\n",
        "        player2.symbol = -1\n",
        "        self.players = [player1, player2]\n",
        "        self.board = Board()\n",
        "        self.wins_over_time = [[0], [0]]\n",
        "        self.explore_exploit_counts = [[], []]\n",
        "\n",
        "    def selfplay(self, rounds=100):\n",
        "        # Entrenamiento mediante self-play (juego contra sí mismos) durante 'rounds' partidas\n",
        "        wins = [0, 0]\n",
        "        for i in tqdm(range(1, rounds + 1)):  #\n",
        "            self.board.reset()\n",
        "            for player in self.players:\n",
        "                player.reset()\n",
        "            game_over = False\n",
        "            while not game_over:  # Mientras la partida no termine\n",
        "                for ix, player in enumerate(self.players):\n",
        "                    # Realizar un movimiento (action) y registrar si fue exploración o explotación\n",
        "                    action, explored = player.move(self.board, explore=True)\n",
        "                    self.explore_exploit_counts[ix].append(1 if explored else 0)  # 1=exploró, 0=explotó\n",
        "                    self.board.update(player.symbol, action)  # Actualizar el tablero con el movimiento\n",
        "                    for player in self.players:\n",
        "                        player.update(self.board)  # Actualizar el estado interno de cada agente\n",
        "                    if self.board.is_game_over() is not None:  # Verificar si la partida terminó\n",
        "                        game_over = True\n",
        "                        break\n",
        "            self.reward()\n",
        "            for ix, player in enumerate(self.players):\n",
        "                if self.board.is_game_over() == player.symbol:\n",
        "                    wins[ix] += 1  # Incrementar victorias del jugador ganador\n",
        "                self.wins_over_time[ix].append(wins[ix])  # Guardar victorias acumuladas\n",
        "        return wins  # Devolver las victorias totales de cada jugador\n",
        "\n",
        "    def reward(self):\n",
        "        winner = self.board.is_game_over()\n",
        "        if winner == 0:  # Empate\n",
        "            for player in self.players:\n",
        "                player.reward(0.5)  # Ambos reciben 0.5\n",
        "        else:\n",
        "            for player in self.players:\n",
        "                if winner == player.symbol:\n",
        "                    player.reward(1)\n",
        "                else:\n",
        "                    player.reward(0)\n"
      ],
      "metadata": {
        "id": "_n-pWCnNDA8k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clase Agente: Representa a un agente que aprende a jugar usando aprendizaje por refuerzo"
      ],
      "metadata": {
        "id": "wjBANw1-DQsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, alpha=0.5, prob_exp=0.5):\n",
        "        self.value_function = {}  # Diccionario para almacenar valores de estados (estado -> valor)\n",
        "        self.alpha = alpha  # Tasa de aprendizaje\n",
        "        self.positions = []  # Lista de estados visitados en una partida\n",
        "        self.prob_exp = prob_exp  # Probabilidad de exploración (ε en ε-greedy)\n",
        "\n",
        "    def reset(self):\n",
        "        self.positions = []\n",
        "\n",
        "    def move(self, board, explore=True):\n",
        "        # Decidir el próximo movimiento del agente\n",
        "        valid_moves = board.valid_moves()  # Obtener columnas válidas\n",
        "        explored = False\n",
        "        if explore and np.random.uniform(0, 1) < self.prob_exp:  # Exploración (ε-greedy)\n",
        "            ix = np.random.choice(len(valid_moves))\n",
        "            return valid_moves[ix], True  # Devuelve columna aleatoria y marca como exploración\n",
        "        # Explotación: elegir el movimiento con mayor valor\n",
        "        max_value = -1000\n",
        "        best_col = valid_moves[0]\n",
        "        for col in valid_moves:\n",
        "            next_board = board.state.copy()\n",
        "            board_copy = Board()\n",
        "            board_copy.state = next_board\n",
        "            board_copy.update(self.symbol, col)  # Simular el movimiento\n",
        "            next_state = str(next_board.reshape(6*7))  # Convertir estado a cadena\n",
        "            value = 0 if self.value_function.get(next_state) is None else self.value_function.get(next_state)\n",
        "            if value >= max_value:\n",
        "                max_value = value\n",
        "                best_col = col\n",
        "        return best_col, False  # Devuelve la mejor columna y marca como explotación\n",
        "\n",
        "    def update(self, board):\n",
        "        # Guardar el estado actual del tablero en la lista de posiciones\n",
        "        self.positions.append(str(board.state.reshape(6*7)))\n",
        "\n",
        "    def reward(self, reward):\n",
        "        # Actualizar los valores de los estados al final de la partida\n",
        "        for p in reversed(self.positions):  # Iterar en orden inverso\n",
        "            if self.value_function.get(p) is None:\n",
        "                self.value_function[p] = 0  # Inicializar valor en 0 si no existe\n",
        "            # Actualizar valor usando aprendizaje por diferencias temporales (TD)\n",
        "            self.value_function[p] += self.alpha * (reward - self.value_function[p])\n",
        "            reward = self.value_function[p]  # Propagar el valor actualizado\n"
      ],
      "metadata": {
        "id": "IxByIyeZDQUU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clase Board: Representa el entorno donde se realizara el juego"
      ],
      "metadata": {
        "id": "daRu68a9DxGc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Hs2x7jYaDgYQ"
      },
      "outputs": [],
      "source": [
        "# Clase Board: Representa el tablero de 4 en raya (6 filas x 7 columnas)\n",
        "class Board:\n",
        "    def __init__(self):\n",
        "        self.rows = 6\n",
        "        self.cols = 7\n",
        "        self.state = np.zeros((self.rows, self.cols), dtype=int)  # Tablero inicial vacío\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.zeros((self.rows, self.cols), dtype=int)\n",
        "\n",
        "    def valid_moves(self):\n",
        "        # Devolver columnas donde se puede jugar (no llenas)\n",
        "        return [col for col in range(self.cols) if self.state[0, col] == 0]\n",
        "\n",
        "    def update(self, symbol, col):\n",
        "        # Colocar una ficha en la columna indicada (cae al fondo)\n",
        "        for row in range(self.rows-1, -1, -1):\n",
        "            if self.state[row, col] == 0:\n",
        "                self.state[row, col] = symbol\n",
        "                break\n",
        "\n",
        "    def is_game_over(self):\n",
        "        # Horizontal\n",
        "        for row in range(self.rows):\n",
        "            for col in range(self.cols-3):\n",
        "                if (self.state[row, col] != 0 and\n",
        "                    self.state[row, col] == self.state[row, col+1] == self.state[row, col+2] == self.state[row, col+3]):\n",
        "                    return self.state[row, col]\n",
        "        # Vertical\n",
        "        for row in range(self.rows-3):\n",
        "            for col in range(self.cols):\n",
        "                if (self.state[row, col] != 0 and\n",
        "                    self.state[row, col] == self.state[row+1, col] == self.state[row+2, col] == self.state[row+3, col]):\n",
        "                    return self.state[row, col]\n",
        "        # Diagonal positiva\n",
        "        for row in range(self.rows-3):\n",
        "            for col in range(self.cols-3):\n",
        "                if (self.state[row, col] != 0 and\n",
        "                    self.state[row, col] == self.state[row+1, col+1] == self.state[row+2, col+2] == self.state[row+3, col+3]):\n",
        "                    return self.state[row, col]\n",
        "        # Diagonal negativa\n",
        "        for row in range(3, self.rows):\n",
        "            for col in range(self.cols-3):\n",
        "                if (self.state[row, col] != 0 and\n",
        "                    self.state[row, col] == self.state[row-1, col+1] == self.state[row-2, col+2] == self.state[row-3, col+3]):\n",
        "                    return self.state[row, col]\n",
        "        # Empate (tablero lleno)\n",
        "        if len(self.valid_moves()) == 0:\n",
        "            return 0\n",
        "        return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejecucion del Entrenamiento"
      ],
      "metadata": {
        "id": "6lhKwa5EEZHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecución del entrenamiento y visualización\n",
        "agent1 = Agent(prob_exp=0.5)\n",
        "agent2 = Agent()\n",
        "\n",
        "game = Game(agent1, agent2)\n",
        "game.selfplay(25000)\n",
        "\n",
        "# Calcular proporción de exploración (promedio móvil para suavizar)\n",
        "def moving_average(data, window_size=1000):\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNliTU0BJbcZ",
        "outputId": "fbbca8c3-aed2-4ec0-c8a3-075f7bd8339c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25000/25000 [05:59<00:00, 69.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar resultados en un DataFrame y mostrarlos\n",
        "funcion_de_valor = sorted(agent1.value_function.items(), key=lambda kv: kv[1], reverse=True)\n",
        "tabla = pd.DataFrame({'estado': [x[0] for x in funcion_de_valor], 'valor': [x[1] for x in funcion_de_valor]})\n",
        "print(tabla)\n",
        "\n",
        "# Guardar la función de valor en un archivo pickle\n",
        "with open('agente_connect4.pickle', 'wb') as handle:\n",
        "    pickle.dump(agent1.value_function, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJGgtFzJEUdL",
        "outputId": "bf2bff1a-02bb-4af7-e60f-df3668270d55"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   estado  valor\n",
            "0       [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...    1.0\n",
            "1       [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...    1.0\n",
            "2       [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...    1.0\n",
            "3       [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...    1.0\n",
            "4       [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...    1.0\n",
            "...                                                   ...    ...\n",
            "321827  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...    0.0\n",
            "321828  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...    0.0\n",
            "321829  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...    0.0\n",
            "321830  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...    0.0\n",
            "321831  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 ...    0.0\n",
            "\n",
            "[321832 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EtmHGjSOKu5l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}